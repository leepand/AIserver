{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file AIFlyLocal.py\n",
    "# -*- coding:utf-8 -*-\n",
    "from model_loader import ModelLoader\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "from AIFlysdk.AIFlyApi import AIFlyApi\n",
    "from model_loader import ModelLoader\n",
    "import yaml\n",
    "\n",
    "class PredictionInput:\n",
    "    \"\"\"\n",
    "    Contains input details and model_id and data\n",
    "    model_id:'tensormodel'\n",
    "    model_version:'0.1.0\n",
    "    data:\n",
    "        - input:数据输入\n",
    "    \"\"\"  \n",
    "    def __init__(self,model_id,model_version,data):\n",
    "        self.model_id=model_id\n",
    "        self.model_version=model_version\n",
    "        self.data=data\n",
    "\n",
    "class ModelInput:\n",
    "    \"\"\"\n",
    "    Contains input details and model_id and data\n",
    "    funcslist:['predpy.pred']\n",
    "        - predpy:文件名\n",
    "        - pred:函数名\n",
    "    \"\"\"  \n",
    "    def __init__(self,funcslist):\n",
    "        self.funcslist=funcslist\n",
    "class PredictServer(object):\n",
    "    def __init__(self,config):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.conf=config#'config/AIFlyapi_config.yaml'\n",
    "        self.models_loaded={}\n",
    "        with open(self.conf, 'rt') as f:\n",
    "            self.client_config = yaml.load(f.read())\n",
    "        self.models_loaded = {}#model_loader.get_models_from_list(models_to_load)\n",
    "\n",
    "    def load_models(self, model_list):\n",
    "        \"\"\"Handles deployed model for init\"\"\"\n",
    "        self.logger.debug('Update models received with payload: %s', str(model_list))\n",
    "        model_loader = ModelLoader(self.client_config)\n",
    "        models_to_load=model_list\n",
    "        self.models_loaded = model_loader.get_models_from_list(models_to_load)\n",
    "        #model_list=[[\"HelloWorldExample\", \"1.0.0\"],[\"HelloAI2\", \"1.0.0\"],[\"TensorflowMnistExample\",\"1.0.0\"],['fib_model',\"1.0.2\"]]\n",
    "        \n",
    "        return json.dumps({\"Init Model Service\": \"Success\"})\n",
    "    def predict(self, payload):\n",
    "        if ('data' in payload.keys()) and ('modelId' in payload.keys()):\n",
    "            PredictionInput.data = payload['data']\n",
    "            PredictionInput.model_id = payload['modelId']\n",
    "            PredictionInput.model_version=payload['model_version']\n",
    "            key = (PredictionInput.model_id, PredictionInput.model_version)\n",
    "            curr_model = self.models_loaded[key]\n",
    "             \n",
    "        else:           \n",
    "            print(\"Bad Request\", \"model_version and(or) modelId missing in the payload\")\n",
    "        try:\n",
    "            po = json.dumps({'result':curr_model.predict(PredictionInput.data)})\n",
    "            return po\n",
    "        except:\n",
    "            return json.dumps({'status': 'Failure', 'message' : 'Error occurred'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting AIFlylocal/AIFlylocal.py\n"
     ]
    }
   ],
   "source": [
    "%%file AIFlylocal/AIFlylocal.py\n",
    "# -*- coding:utf-8 -*-\n",
    "from model_loader import ModelLoader\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "from AIFlysdk.AIFlyApi import AIFlyApi\n",
    "from model_loader import ModelLoader\n",
    "import yaml\n",
    "\n",
    "class PredictionInput:\n",
    "    \"\"\"\n",
    "    Contains input details and model_id and data\n",
    "    model_id:'tensormodel'\n",
    "    model_version:'0.1.0\n",
    "    data:\n",
    "        - input:数据输入\n",
    "    \"\"\"  \n",
    "    def __init__(self,model_id,model_version,data):\n",
    "        self.model_id=model_id\n",
    "        self.model_version=model_version\n",
    "        self.data=data\n",
    "\n",
    "class ModelInput:\n",
    "    \"\"\"\n",
    "    Contains input details and model_id and data\n",
    "    funcslist:['predpy.pred']\n",
    "        - predpy:文件名\n",
    "        - pred:函数名\n",
    "    \"\"\"  \n",
    "    def __init__(self,funcslist):\n",
    "        self.funcslist=funcslist\n",
    "class PredictServer(object):\n",
    "    def __init__(self,config):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.conf=config#'config/AIFlyapi_config.yaml'\n",
    "        self.models_loaded={}\n",
    "        with open(self.conf, 'rt') as f:\n",
    "            self.client_config = yaml.load(f.read())\n",
    "        self.models_loaded = {}#model_loader.get_models_from_list(models_to_load)\n",
    "\n",
    "    def load_models(self, model_list):\n",
    "        \"\"\"Handles deployed model for init\"\"\"\n",
    "        self.logger.debug('Update models received with payload: %s', str(model_list))\n",
    "        model_loader = ModelLoader(self.client_config)\n",
    "        models_to_load=model_list\n",
    "        self.models_loaded = model_loader.get_models_from_list(models_to_load)\n",
    "        #model_list=[[\"HelloWorldExample\", \"1.0.0\"],[\"HelloAI2\", \"1.0.0\"],[\"TensorflowMnistExample\",\"1.0.0\"],['fib_model',\"1.0.2\"]]\n",
    "        \n",
    "        return json.dumps({\"Init Model Service\": \"Success\"})\n",
    "    def predict(self, *args,**kwargs):\n",
    "        #PredictionInput.data = *args\n",
    "        if ('model_version' in kwargs.keys()) and ('modelId' in kwargs.keys()):   \n",
    "            PredictionInput.model_id = kwargs['modelId']\n",
    "            PredictionInput.model_version=kwargs['model_version']\n",
    "            key = (PredictionInput.model_id, PredictionInput.model_version)\n",
    "            curr_model = self.models_loaded[key]\n",
    "             \n",
    "        else:           \n",
    "            print(\"Bad Request\", \"model_version and(or) modelId missing in the payload\")\n",
    "        try:\n",
    "            po = json.dumps({'result':curr_model.predict(*args)})\n",
    "            return po\n",
    "        except:\n",
    "            return json.dumps({'status': 'Failure', 'message' : 'Error occurred'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local_server=PredictServer('config/AIFlyapi_config.yaml')\n",
    "load_model=model_local_server.load_models([[\"fib_model\", \"1.0.2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"status\": \"Failure\", \"message\": \"Error occurred\"}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {'modelId':'fib_model','model_version':'1.0.2', 'data':{'n':2}}\n",
    "\n",
    "model_local_server.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\": 17711}'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from AIFlylocal.AIFlylocal import PredictServer\n",
    "model_local_server=PredictServer('config/AIFlyapi_config.yaml')\n",
    "load_model=model_local_server.load_models([[\"fib_model\", \"1.0.2\"]])\n",
    "\n",
    "param = {'modelId':'fib_model','model_version':'1.0.2'}\n",
    "\n",
    "\n",
    "model_local_server.predict(21,modelId='fib_model',model_version='1.0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 1} {}\n"
     ]
    }
   ],
   "source": [
    "def request(**kwargs):\n",
    "    data, files = decouple_files(kwargs)\n",
    "    print data, files \n",
    "def decouple_files(kwargs):\n",
    "    data = {arg: value for arg, value in kwargs.items() if not is_file(value)}\n",
    "    files = {arg: value for arg, value in kwargs.items() if is_file(value)}\n",
    "    return data, files\n",
    "\n",
    "def is_file(value):\n",
    "    return hasattr(value, 'read') or hasattr(value, 'readlines')\n",
    "request(c=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "([3, 13], 'd')\n",
      "{'e': 5, 'd': '4'} ['e', 'd']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test(a,*args,**kwargs):\n",
    "    print a\n",
    "    #print b\n",
    "    #print c\n",
    "    print args\n",
    "    print kwargs,kwargs.keys()\n",
    "test(1,[3,13],'d',d='4',e=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fib() takes exactly 1 argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-41884f288c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mfib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-41884f288c1f>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mfib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fib() takes exactly 1 argument (2 given)"
     ]
    }
   ],
   "source": [
    "def fib(n):\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "def test(*args):\n",
    "    print args\n",
    "    print fib(*args)\n",
    "test(3,2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def fib(x,y):\n",
    "    return x+y\n",
    "def test(*args):\n",
    "    print args\n",
    "    print fib(*args)\n",
    "test(3,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AIFlyLocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "class Client:\n",
    "    def __init__(self, server_url, auth_token=None):\n",
    "        # strip trailing / to avoid double / chars in the URL\n",
    "        self.server_url = server_url.rstrip(\"/\")\n",
    "        self.auth_token = auth_token\n",
    "        self._metadata = None\n",
    "\n",
    "    def __getattr__(self, func_name):\n",
    "        return RemoteFunction(self, func_name)\n",
    "\n",
    "    def call_func(self, func_name, **kwargs):\n",
    "        path = self._get_path(func_name)\n",
    "        return self.request(path, **kwargs)\n",
    "    def request(self, _path, **kwargs):\n",
    "        url = self.server_url + _path\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            headers = self.prepare_headers()\n",
    "            data, files = self.decouple_files(kwargs)\n",
    "            if files:\n",
    "                response = requests.post(url, data=data, files=files, headers=headers, stream=True)\n",
    "            else:\n",
    "                response = requests.post(url, json=data, headers=headers, stream=True)\n",
    "        except ConnectionError:\n",
    "            raise FireflyError('Unable to connect to the server, please try again later.')\n",
    "        finally:\n",
    "            t1 = time.time()\n",
    "            logger.info(\"%0.3f: POST %s\", t1-t0, url)\n",
    "            return self.handle_response(response)\n",
    "    def decouple_files(self, kwargs):\n",
    "        data = {arg: value for arg, value in kwargs.items() if not self.is_file(value)}\n",
    "        files = {arg: value for arg, value in kwargs.items() if self.is_file(value)}\n",
    "        return data, files\n",
    "\n",
    "    def is_file(self, value):\n",
    "        return hasattr(value, 'read') or hasattr(value, 'readlines')\n",
    "\n",
    "def RemoteFunction(client, func_name):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        if args:\n",
    "            raise AIflyError('Firefly functions only accept named arguments')\n",
    "        return client.call_func(func_name, **kwargs)\n",
    "    wrapped.__name__ = func_name\n",
    "    wrapped.__qualname__ = func_name\n",
    "    wrapped.__doc__ = client.get_doc(func_name)\n",
    "    return wrapped\n",
    "\n",
    "class AIflyError(Exception):\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
